{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "upper-milton",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "# vgg = models.resnet50()\n",
    "# summary(vgg, (3, 542, 1042))\n",
    "\n",
    "\"\"\"\n",
    "The following is an import of PyTorch libraries.\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm import trange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ignored-prescription",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dedbe46019174cc88ac5f3da7006c52f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "l = [None] * 10000\n",
    "\n",
    "for i, e in tqdm(enumerate(l), total = len(l)): \n",
    "    time.sleep(0.01\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "historical-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Determine if any GPUs are available\n",
    "\"\"\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "conceptual-chicago",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A Convolutional Variational Autoencoder\n",
    "\"\"\"\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, imgChannels=1, featureDim=32*20*20, zDim=256):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # Initializing the 2 convolutional layers and 2 full-connected layers for the encoder\n",
    "        self.encConv1 = nn.Conv2d(imgChannels, 16, 5)\n",
    "        self.encConv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.encFC1 = nn.Linear(featureDim, zDim)\n",
    "        self.encFC2 = nn.Linear(featureDim, zDim)\n",
    "\n",
    "        # Initializing the fully-connected layer and 2 convolutional layers for decoder\n",
    "        self.decFC1 = nn.Linear(zDim, featureDim)\n",
    "        self.decConv1 = nn.ConvTranspose2d(32, 16, 5)\n",
    "        self.decConv2 = nn.ConvTranspose2d(16, imgChannels, 5)\n",
    "\n",
    "    def encoder(self, x):\n",
    "\n",
    "        # Input is fed into 2 convolutional layers sequentially\n",
    "        # The output feature map are fed into 2 fully-connected layers to predict mean (mu) and variance (logVar)\n",
    "        # Mu and logVar are used for generating middle representation z and KL divergence loss\n",
    "        x = F.relu(self.encConv1(x))\n",
    "        x = F.relu(self.encConv2(x))\n",
    "        x = x.view(-1, 32*20*20)\n",
    "        mu = self.encFC1(x)\n",
    "        logVar = self.encFC2(x)\n",
    "        return mu, logVar\n",
    "\n",
    "    def reparameterize(self, mu, logVar):\n",
    "\n",
    "        #Reparameterization takes in the input mu and logVar and sample the mu + std * eps\n",
    "        std = torch.exp(logVar/2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + std * eps\n",
    "\n",
    "    def decoder(self, z):\n",
    "\n",
    "        # z is fed back into a fully-connected layers and then into two transpose convolutional layers\n",
    "        # The generated output is the same size of the original input\n",
    "        x = F.relu(self.decFC1(z))\n",
    "        x = x.view(-1, 32, 20, 20)\n",
    "        x = F.relu(self.decConv1(x))\n",
    "        x = torch.sigmoid(self.decConv2(x))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # The entire pipeline of the VAE: encoder -> reparameterization -> decoder\n",
    "        # output, mu, and logVar are returned for loss computation\n",
    "        mu, logVar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logVar)\n",
    "        out = self.decoder(z)\n",
    "        return out, mu, logVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "confidential-bhutan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/469 [00:00<?, ?batch/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 0/469 [00:00<?, ?batch/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cabe0006/opt/anaconda3/envs/bb_pipeline_test/lib/python3.7/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 0/469 [00:00<?, ?batch/s, loss=6.84e+4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 0/469 [00:00<?, ?batch/s, loss=6.84e+4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 0/469 [00:00<?, ?batch/s, loss=6.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 0/469 [00:00<?, ?batch/s, loss=6.44e+4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 0/469 [00:01<?, ?batch/s, loss=5.86e+4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 0/469 [00:01<?, ?batch/s, loss=5.86e+4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 0/469 [00:01<?, ?batch/s, loss=5.66e+4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 0/469 [00:01<?, ?batch/s, loss=5.66e+4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 0/469 [00:02<?, ?batch/s, loss=5.71e+4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 0/469 [00:02<?, ?batch/s, loss=5.71e+4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 0/469 [00:02<?, ?batch/s, loss=5.62e+4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 0/469 [00:02<?, ?batch/s, loss=5.62e+4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 0/469 [00:02<?, ?batch/s, loss=5.68e+4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 0/469 [00:02<?, ?batch/s, loss=5.68e+4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 0/469 [00:03<?, ?batch/s, loss=5.41e+4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 0/469 [00:03<?, ?batch/s, loss=5.41e+4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 0/469 [00:03<?, ?batch/s, loss=5.34e+4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 0/469 [00:03<?, ?batch/s, loss=5.34e+4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 0/469 [00:04<?, ?batch/s, loss=5.32e+4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 0/469 [00:04<?, ?batch/s, loss=5.32e+4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 0/469 [00:04<?, ?batch/s, loss=5.28e+4]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Epoch 0:   0%|          | 0/469 [00:04<?, ?batch/s, loss=5.28e+4]\u001b[A\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-fb7dd2b5572d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m# Backpropagation based on the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mtepoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bb_pipeline_test/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bb_pipeline_test/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Initialize Hyperparameters\n",
    "\"\"\"\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Create dataloaders to feed data into the neural network\n",
    "Default MNIST dataset is used and standard train/test split is performed\n",
    "\"\"\"\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('/Users/cabe0006/Projects/monash/data', train=True, download=True,\n",
    "                    transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('/Users/cabe0006/Projects/monash/data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=1)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Initialize the network and the Adam optimizer\n",
    "\"\"\"\n",
    "net = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Training the network for a given number of epochs\n",
    "The loss after every epoch is printed\n",
    "\"\"\"\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "        for idx, data in enumerate(train_loader, 0):\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "            imgs, _ = data\n",
    "            imgs = imgs.to(device)\n",
    "\n",
    "            # Feeding a batch of images into the network to obtain the output image, mu, and logVar\n",
    "            out, mu, logVar = net(imgs)\n",
    "\n",
    "            # The loss is the BCE loss combined with the KL divergence to ensure the distribution is learnt\n",
    "            kl_divergence = 0.5 * torch.sum(-1 - logVar + mu.pow(2) + logVar.exp())\n",
    "            loss = F.binary_cross_entropy(out, imgs, size_average=False) + kl_divergence\n",
    "\n",
    "            # Backpropagation based on the loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tepoch.set_postfix(loss=loss.item())\n",
    "    print('Epoch {}: Loss {}'.format(epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "killing-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(vae, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for data in random.sample(list(test_loader), 1):\n",
    "        imgs, _ = data\n",
    "        imgs = imgs.to(device)\n",
    "        img = np.transpose(imgs[0].cpu().numpy(), [1,2,0])\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(np.squeeze(img))\n",
    "        out, mu, logVAR = net(imgs)\n",
    "        outimg = np.transpose(out[0].cpu().numpy(), [1,2,0])\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(np.squeeze(outimg))\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bb_pipeline_test",
   "language": "python",
   "name": "bb_pipeline_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
