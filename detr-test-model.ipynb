{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "widespread-grave",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "finnish-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-margin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-occasions",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "premium-picture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='/Users/cabe0006/Projects/monash/data/cifar', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "signed-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, l = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "metallic-safety",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 32, 32])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "corporate-messenger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9765)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cardiac-tracy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(i/2 + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-makeup",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "# print(' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_vae.encoder import build_encoder\n",
    "from models_vae.decoder import build_decoder\n",
    "import torch\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = build_encoder(args)\n",
    "encoder(torch.rand(1, 3, 32, 32)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder = build_decoder()\n",
    "# decoder(torch.rand(1, 2048, 1, 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-occasion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-running",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_vae.vae import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = build({})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-gateway",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae(torch.rand(1, 3, 32, 32))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-associate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-dominican",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-rouge",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_vae.vae_resnet import build\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    backbone = 'resnet50'\n",
    "    dilation = False\n",
    "    \n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build(args)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/experiment_1')\n",
    "writer.add_graph(model, torch.rand(2, 3, 542, 1024))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(model, (3, 542, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-overall",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_vae.encoder import build_encoder\n",
    "from models_vae.decoder import build_decoder\n",
    "import torch\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-council",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-vintage",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = build_encoder(args)\n",
    "encoder(torch.rand(1, 3, 542, 1024))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-seeking",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sum(p.numel() for p in encoder.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = build_decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder(torch.rand(1, 2048, 17, 32)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in decoder.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-decision",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-prior",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-salon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-spirituality",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-large",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-netherlands",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-muslim",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-exclusion",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "# vgg = models.resnet50()\n",
    "# summary(vgg, (3, 542, 1042))\n",
    "\n",
    "\"\"\"\n",
    "The following is an import of PyTorch libraries.\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm import trange\n",
    "import util.misc as utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 3, 512, 271)\n",
    "print(input.size())\n",
    "downsample = nn.Conv2d(3, 16, 3, stride=2, padding=1)\n",
    "upsample = nn.ConvTranspose2d(16, 3, 3, stride=2, padding=1)\n",
    "same = nn.Conv2d(16, 16, 3, padding=1)\n",
    "\n",
    "h = downsample(input)\n",
    "print(h.size())\n",
    "s = same(h)\n",
    "print(s.size())\n",
    "output = upsample(s, output_size=input.size())\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 3, 512, 271)\n",
    "same = nn.Conv2d(3, 3, 3, padding=1)\n",
    "h = same(input)\n",
    "print(h.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-pepper",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-tracker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Determine if any GPUs are available\n",
    "\"\"\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A Convolutional Variational Autoencoder\n",
    "\"\"\"\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, imgChannels=3, featureDim=32*20*20, zDim=256):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # Initializing the 2 convolutional layers and 2 full-connected layers for the encoder\n",
    "#         self.encConv1 = nn.Conv2d(imgChannels, 16, 5)\n",
    "#         self.encConv2 = nn.Conv2d(16, 32, 5)\n",
    "#         self.pool = nn.AdaptiveMaxPool2d((20, 20))\n",
    "\n",
    "#         self.encFC1 = nn.Linear(featureDim, zDim)\n",
    "#         self.encFC2 = nn.Linear(featureDim, zDim)\n",
    "\n",
    "#         # Initializing the fully-connected layer and 2 convolutional layers for decoder\n",
    "#         self.decFC1 = nn.Linear(zDim, featureDim)\n",
    "#         self.decConv1 = nn.ConvTranspose2d(32, 16, 5)\n",
    "#         self.decConv2 = nn.ConvTranspose2d(16, imgChannels, 5)\n",
    "        \n",
    "        \n",
    "        self.down1 = nn.Conv2d(imgChannels, 16, 3, stride=2, padding=1)\n",
    "        self.down2 = nn.Conv2d(16, 16, 3, stride=2, padding=1)\n",
    "        self.down3 = nn.Conv2d(16, 16, 3, stride=2, padding=1)\n",
    "        \n",
    "        self.same1 = nn.Conv2d(16, 16, 3, padding=1)\n",
    "        self.same2 = nn.Conv2d(16, 16, 3, padding=1)\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose2d(16, 16, 3, stride=2, padding=1)\n",
    "        self.up2 = nn.ConvTranspose2d(16, 16, 3, stride=2, padding=1)\n",
    "        self.up4 = nn.ConvTranspose2d(16, 32, 3, stride=2, padding=1)\n",
    "        self.up3 = nn.ConvTranspose2d(32, imgChannels, 3, stride=2, padding=1)\n",
    "\n",
    "    def encoder(self, x):\n",
    "\n",
    "        # Input is fed into 2 convolutional layers sequentially\n",
    "        # The output feature map are fed into 2 fully-connected layers to predict mean (mu) and variance (logVar)\n",
    "        # Mu and logVar are used for generating middle representation z and KL divergence loss\n",
    "        x = F.relu(self.down1(x))\n",
    "        x = F.relu(self.down2(x))\n",
    "        x = F.relu(self.down3(x))\n",
    "        mu = self.same1(x)\n",
    "        logVar = self.same2(x)\n",
    "        return mu, logVar\n",
    "\n",
    "    def reparameterize(self, mu, logVar):\n",
    "\n",
    "        #Reparameterization takes in the input mu and logVar and sample the mu + std * eps\n",
    "        std = torch.exp(logVar/2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + std * eps\n",
    "\n",
    "    def decoder(self, z):\n",
    "\n",
    "        # z is fed back into a fully-connected layers and then into two transpose convolutional layers\n",
    "        # The generated output is the same size of the original input\n",
    "        x = F.relu(self.up1(z, output_size=(136, 256)))\n",
    "#         x = F.relu(self.up2(z))\n",
    "        x = F.relu(self.up4(x, output_size=(271, 512)))\n",
    "        x = torch.sigmoid(self.up3(x, output_size=(542, 1024)))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # The entire pipeline of the VAE: encoder -> reparameterization -> decoder\n",
    "        # output, mu, and logVar are returned for loss computation\n",
    "        mu, logVar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logVar)\n",
    "        print(\"********\")\n",
    "        print(z.shape)\n",
    "        out = self.decoder(z)\n",
    "        return  mu, logVar, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = VAE().to(device)\n",
    "summary(net, (3, 542, 1024))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-titanium",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import build_dataset, get_coco_api_from_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    \n",
    "    dataset_file = 'vae_ant'\n",
    "    data_path = '/Users/cabe0006/Projects/monash/cvpr_data/detection_dataset/local_env'\n",
    "    masks=False\n",
    "    \n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-fence",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = build_dataset(image_set='test', args=args)\n",
    "# img1 = dataset_train[100][0].numpy()\n",
    "# img = np.moveaxis(img1, [0, 1 ,2 ], [2, 0, 1])\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_train = torch.utils.data.RandomSampler(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sampler_train = torch.utils.data.BatchSampler(\n",
    "        sampler_train, 8, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = DataLoader(dataset_train, batch_sampler=batch_sampler_train,\n",
    "                                   collate_fn=utils.collate_fn, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-blind",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(data_loader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0].tensors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-market",
   "metadata": {},
   "source": [
    "# Dataset testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-casino",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import util.misc as utils\n",
    "from datasets import build_dataset\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    \n",
    "    dataset_file = 'vae_ant'\n",
    "    data_path = '/Users/cabe0006/Projects/monash/cvpr_data/detection_dataset/local_env'\n",
    "    masks=False\n",
    "    \n",
    "args=Args()\n",
    "invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                     std = [ 1/0.229, 1/0.224, 1/0.225 ]),\n",
    "                                transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ],\n",
    "                                                     std = [ 1., 1., 1. ]),\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = build_dataset(image_set='train', args=args)\n",
    "sampler_train = torch.utils.data.RandomSampler(dataset_train)\n",
    "batch_sampler_train = torch.utils.data.BatchSampler(\n",
    "        sampler_train, 2, drop_last=True)\n",
    "data_loader_train = DataLoader(dataset_train, batch_sampler=batch_sampler_train,\n",
    "                                    num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = next(iter(data_loader_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-skirt",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = next(iter(data_loader_train))\n",
    "inv_img = invTrans(imgs[0])\n",
    "s = inv_img.numpy()\n",
    "s = np.moveaxis(s, [0, 1, 2], [2, 0, 1])\n",
    "print(s.shape)\n",
    "\n",
    "plt.imshow(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-enclosure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-philosophy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "other-dylan",
   "metadata": {},
   "source": [
    "# VAE Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-school",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "q = torch.distributions.Normal(2, 4)\n",
    "z = q.rsample()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.distributions.Normal(0, 1)\n",
    "log_pz = p.log_prob(z)\n",
    "log_qzx = q.log_prob(z)\n",
    "print(f'log prob pz: {log_pz}, prob: {torch.exp(log_pz)}')\n",
    "print(f'log prob pz: {log_qzx}, prob: {torch.exp(log_qzx)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-knock",
   "metadata": {},
   "source": [
    "# ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-layout",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "import torch\n",
    "from pl_bolts.models.autoencoders.components import (\n",
    "    resnet18_decoder,\n",
    "    resnet18_encoder,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self,  enc_out_dim=512, latent_dim=256, input_height=542):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = resnet18_encoder(False, False)\n",
    "        self.decoder = resnet18_decoder(\n",
    "            latent_dim=latent_dim,\n",
    "            input_height=input_height,\n",
    "            first_conv=False,\n",
    "            maxpool1=False\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(enc_out_dim, latent_dim)\n",
    "        self.fc_var = nn.Linear(enc_out_dim, latent_dim)\n",
    "#         self.decoder = resnet18_decoder(False, False)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        # Input is fed into 2 convolutional layers sequentially\n",
    "        # The output feature map are fed into 2 fully-connected layers to predict mean (mu) and variance (logVar)\n",
    "        # Mu and logVar are used for generating middle representation z and KL divergence loss\n",
    "        x_encoded = self.encoder(x)\n",
    "        mu, log_var = self.fc_mu(x_encoded), self.fc_var(x_encoded)\n",
    "        return mu, log_var\n",
    "\n",
    "    def reparameterize(self, mu, logVar):\n",
    "        # Reparameterization takes in the input mu and logVar and sample the mu + std * eps\n",
    "        std = torch.exp(logVar / 2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + std * eps\n",
    "\n",
    "    def decoder(self, z):\n",
    "        # z is fed back into a fully-connected layers and then into two transpose convolutional layers\n",
    "        # The generated output is the same size of the original input\n",
    "        x = self.decoder(z)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # The entire pipeline of the VAE: encoder -> reparameterization -> decoder\n",
    "        # output, mu, and logVar are returned for loss computation\n",
    "        mu, logVar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logVar)\n",
    "        out = self.decoder(z)\n",
    "        return out, mu, logVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-portrait",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "# vgg = models.resnet50()\n",
    "# summary(vgg, (3, 542, 1042))\n",
    "vae = VAE()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(vae, (3, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-humor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-completion",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = resnet18_encoder(False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.rand(1, 3, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-force",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder(inp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-humanity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bb_pipeline_test",
   "language": "python",
   "name": "bb_pipeline_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
